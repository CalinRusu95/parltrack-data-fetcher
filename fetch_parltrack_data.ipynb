{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1S4JNyS57LU4PJW1mSv__7SitGdtYHm0l",
      "authorship_tag": "ABX9TyN2XbdM3In4wGqWdPojD4mC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CalinRusu95/parltrack-data-fetcher/blob/main/fetch_parltrack_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required libraries\n",
        "!pip install requests zstandard"
      ],
      "metadata": {
        "id": "i3LBGWng0wcK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import zstandard as zstd\n",
        "import json\n",
        "import os\n",
        "from google.oauth2.service_account import Credentials\n",
        "from googleapiclient.discovery import build\n",
        "from googleapiclient.http import MediaFileUpload\n",
        "from bs4 import BeautifulSoup\n",
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "Gh7Je0ut02Kw"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Constants\n",
        "CREDENTIALS_PATH = \"/tmp/credentials.json\"\n",
        "LOG_FILE_PATH = f\"/tmp/fetch_and_upload_log_{datetime.now().strftime('%Y%m%d')}.txt\"\n",
        "DRIVE_FOLDER_ID = \"16QmR40u_BF8K_DCSttSEOxYidzsuEkTU\"  # Replace with your Google Drive folder ID\n",
        "PARLTRACK_DUMPS_URL = \"https://parltrack.eu/dumps/\""
      ],
      "metadata": {
        "id": "oREgKgBVCelg"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Write credentials from the secret\n",
        "def write_credentials(secret):\n",
        "    with open(CREDENTIALS_PATH, \"w\") as f:\n",
        "        f.write(secret)\n",
        "\n",
        "# Authenticate with Google Drive API\n",
        "def authenticate_google_drive():\n",
        "    credentials = Credentials.from_service_account_file(\n",
        "        CREDENTIALS_PATH,\n",
        "        scopes=[\"https://www.googleapis.com/auth/drive\"]\n",
        "    )\n",
        "    service = build(\"drive\", \"v3\", credentials=credentials)\n",
        "    return service\n",
        "\n",
        "# Upload file to Google Drive\n",
        "def upload_to_drive(service, file_path, file_name):\n",
        "    try:\n",
        "        file_metadata = {\n",
        "            \"name\": file_name,\n",
        "            \"parents\": [DRIVE_FOLDER_ID]\n",
        "        }\n",
        "        media = MediaFileUpload(file_path, resumable=True)\n",
        "        uploaded_file = service.files().create(body=file_metadata, media_body=media, fields=\"id\").execute()\n",
        "        print(f\"Uploaded file ID: {uploaded_file.get('id')}\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        log_error(f\"Failed to upload {file_name} to Google Drive: {e}\")\n",
        "        return False\n",
        "\n",
        "# Fetch, decompress, and upload files\n",
        "def fetch_and_upload_files():\n",
        "    try:\n",
        "        # Fetch the list of available files\n",
        "        response = requests.get(PARLTRACK_DUMPS_URL)\n",
        "        response.raise_for_status()\n",
        "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "\n",
        "        # Extract all .zst file URLs\n",
        "        file_urls = [\n",
        "            PARLTRACK_DUMPS_URL + link[\"href\"]\n",
        "            for link in soup.find_all(\"a\", href=True)\n",
        "            if link[\"href\"].endswith(\".zst\")\n",
        "        ]\n",
        "\n",
        "        # Authenticate with Google Drive\n",
        "        drive_service = authenticate_google_drive()\n",
        "\n",
        "        # Process each file\n",
        "        for file_url in file_urls:\n",
        "            try:\n",
        "                print(f\"Processing file: {file_url}\")\n",
        "\n",
        "                # Fetch the compressed file\n",
        "                response = requests.get(file_url, stream=True)\n",
        "                response.raise_for_status()\n",
        "\n",
        "                # Decompress Zstandard data\n",
        "                dctx = zstd.ZstdDecompressor()\n",
        "                decompressed = dctx.stream_reader(response.raw)\n",
        "\n",
        "                # Parse JSON\n",
        "                data = json.load(decompressed)\n",
        "\n",
        "                # Save the file locally\n",
        "                file_name = os.path.basename(file_url).replace(\".json.zst\", \".json\")\n",
        "                file_path = os.path.join(\"/tmp\", file_name)\n",
        "                with open(file_path, \"w\") as f:\n",
        "                    json.dump(data, f)\n",
        "\n",
        "                # Upload the file to Google Drive\n",
        "                success = upload_to_drive(drive_service, file_path, file_name)\n",
        "\n",
        "                # Clean up the local file\n",
        "                os.remove(file_path)\n",
        "\n",
        "                if success:\n",
        "                    print(f\"Finished processing: {file_name}\")\n",
        "                else:\n",
        "                    log_error(f\"Failed to process {file_name} from {file_url}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                log_error(f\"Error processing file {file_url}: {e}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        log_error(f\"Critical error fetching files: {e}\")\n",
        "\n",
        "# Log errors to a file\n",
        "def log_error(message):\n",
        "    with open(LOG_FILE_PATH, \"a\") as log_file:\n",
        "        log_file.write(f\"{datetime.now().isoformat()} - {message}\\n\")\n",
        "    print(f\"Logged error: {message}\")\n",
        "\n",
        "# Run the process\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        # Read the secret from an environment variable (provided by GitHub Actions)\n",
        "        secret = os.getenv(\"GOOGLE_CREDENTIALS\")\n",
        "        if not secret:\n",
        "            raise ValueError(\"GOOGLE_CREDENTIALS secret is missing!\")\n",
        "\n",
        "        # Write the secret to a temporary file\n",
        "        write_credentials(secret)\n",
        "\n",
        "        # Fetch and upload files\n",
        "        fetch_and_upload_files()\n",
        "\n",
        "    finally:\n",
        "        # Clean up credentials and print log file location\n",
        "        if os.path.exists(CREDENTIALS_PATH):\n",
        "            os.remove(CREDENTIALS_PATH)\n",
        "        print(f\"Log file saved at: {LOG_FILE_PATH}\")"
      ],
      "metadata": {
        "id": "PDw0tCL-DCLN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
